# This file was automatically generated by Cerebrium as a starting point for your project. 
# You can edit it as you wish.
# If you would like to learn more about your Cerebrium config, please visit https://docs.cerebrium.ai/cerebrium/environments/initial-setup#config-file-example

[cerebrium.build]
predict_data = "{\"prompt\": \"Here is some example predict data for your config.yaml which will be used to test your predict function on build.\"}"
log_level = "INFO"
disable_confirmation = true

[cerebrium.deployment]
name = "prebuilt-llama2-70b"
python_version = "3.10"
include = "[./*, main.py, requirements.txt, pkglist.txt, conda_pkglist.txt]"
exclude = "[./.*, ./__*]"

[cerebrium.hardware]
gpu = "AMPERE_A6000"
cpu = 9
memory = 30
gpu_count = 1

[cerebrium.scaling]
min_replicas = 4
cooldown = 600

[cerebrium.dependencies.pip]
ray = "latest"
transformers = "latest"
bitsandbytes = "latest"
peft = "latest"
torch = "latest"
numpy = "latest"
pydantic = "latest"
huggingface_hub = "latest"
safetensors = "latest"
accelerate = "latest"
scipy = "latest"
sentencepiece = "latest"
hf_transfer = "latest"
optimum = "latest"
protobuf = "latest"

[cerebrium.dependencies.conda]

[cerebrium.dependencies.apt]
