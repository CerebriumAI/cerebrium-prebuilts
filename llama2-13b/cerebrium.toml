# This file was automatically generated by Cerebrium as a starting point for your project. 
# You can edit it as you wish.
# If you would like to learn more about your Cerebrium config, please visit https://docs.cerebrium.ai/cerebrium/environments/initial-setup#config-file-example

[cerebrium.build]
predict_data = "{\"prompt\": \"Here is some example predict data for your config.yaml which will be used to test your predict function on build.\"}"
disable_animation = true
log_level = "INFO"
disable_confirmation = true

[cerebrium.deployment]
name = "prebuilt-llama2-13b"
python_version = "3.10"
include = "[./*, main.py, requirements.txt, pkglist.txt, conda_pkglist.txt]"
exclude = "[./.*, ./__*]"

[cerebrium.hardware]
gpu = "AMPERE_A6000"
cpu = 2
memory = 16.0
gpu_count = 1

[cerebrium.scaling]
min_replicas = 0
cooldown = 60

[cerebrium.dependencies.pip]
"git+https://github.com/huggingface/peft.git" = "latest"
"git+https://github.com/huggingface/transformers.git" = "latest"
"git+https://github.com/huggingface/accelerate.git" = "latest"
bitsandbytes = "latest"
evaluate = "latest"
numpy = "latest"
sentencepiece = "latest"
datasets = "latest"
torch = "latest"
scipy = "latest"
huggingface_hub = "latest"
protobuf = "latest"
pydantic = "latest"

[cerebrium.dependencies.conda]

[cerebrium.dependencies.apt]
git = "latest"
